(* Written by Eric Hall *)

open HolKernel Parse boolLib bossLib;

val _ = new_theory "thingsToDiscuss";

(* -------------------------------------------------------------------------- *)
(* MIT lectures on convolutional codes                                        *)
(* -------------------------------------------------------------------------- *)
(* Content:                                                                   *)
(*                                                                            *)
(* A sliding window is moved over the input (this is why the code is called   *)
(* convolutional). At each position a number of parity bits are generated.    *)
(* These parity bits comprise the output.                                     *)
(*                                                                            *)
(* The constraint length K denotes the size of the sliding window             *)
(*                                                                            *)
(* If r bits are generated at each position, then the output will be r times  *)
(* the size of the original, and the code rate will be 1/r, as 1 bit of the   *)
(* original message is transmitted per r bits of the encoded message.         *)
(*                                                                            *)
(* In a given window, the parity bits are generated using partity equations,  *)
(* which are polynomials over the elements of the window, in modulo 2.        *)
(*                                                                            *)
(* Convolutional coding can be viewed in terms of a block diagram, which      *)
(* effectively interprets the algorithm in the aforementioned way, as outputs *)
(* generated from polynomials                                                 *)
(*                                                                            *)
(* It can also be viewed from a state machine perspective, where each state   *)
(* represents the past few perceived bits, and each transition refers to the  *)
(* bit that was read in this state and the bits that were output in this      *)
(* state, as the polynomials will always output the same bit if they are in   *)
(* the same state.                                                            *)
(*                                                                            *)
(* Typically starts from the state which perceived two zeros beforehand       *)
(*                                                                            *)
(* The above is sufficient for encoding                                       *)
(*                                                                            *)
(* Decoding through maximum likelihood decoding. This is equivalent to        *)
(* finding the nearest valid codeword in terms of Hamming distance.           *)
(*                                                                            *)
(* The trellis is a structure that contains the state at each time step,      *)
(* and transitions from states at each time step to the corresponding states  *)
(* at the next time step. Basically adds time information to the state        *)
(* machine.                                                                   *)
(*                                                                            *)
(* Hard decision decoding is basically digital whereas soft decision decoding *)
(* is basically analog. This algorithm is typically implemented on the        *)
(* circuit level, where we have voltages rather than binary 1s and 0s. Soft   *)
(* decoding improves error correcting performance.                            *)
(*                                                                            *)
(* Want to find a path through the trellis that most closely approximates the *)
(* received message.                                                          *)
(*                                                                            *)
(* Branch metric: Hamming distance between output of a particular transition  *)
(* and the received message at that point.                                    *)
(*                                                                            *)
(* Path metric: the minimum sum of branch metrics on any path in order to get *)
(* to a particular state.                                                     *)
(*                                                                            *)
(* The Viterbi algorithm basically just applies dynamic programming to the    *)
(* trellis in order to minimize the path metric at each state and time. The   *)
(* path metric of any state at a given time is dependent on and only on the   *)
(* path metrics of all states at the previous point in time.                  *)
(*                                                                            *)
(* Downside: decoding time exponential in K, the constraint length            *)
(*                                                                            *)
(* Downside: decoding time for first bit requires the entire path to be built *)
(*                                                                            *)
(* In practice, starting decoding at 5 * K bits is a reasonable decoding      *)
(* window, because beyond this point it's unlikely for further future         *)
(* knowledge to affect the optimal first move on the path                     *)
(*                                                                            *)
(* My own observation: surely at some point, the optimal first move will be   *)
(* optimal on a path towards each state, and at that point you could take     *)
(* that step confidently?                                                     *)
(*                                                                            *)
(* BCJR or Fano's sequential decoding scheme may be used to decode for large  *)
(* K.                                                                         *)
(* -------------------------------------------------------------------------- *)
(* Questions/things to discuss:                                               *)
(*                                                                            *)
(* Using analog encoding gives better performance than using digital encoding.*)
(* Should I use analog encoding? Seems like the hardware/electronics side of  *)
(* things is outside my area of expertise.                                    *)
(*                                                                            *)
(* Relatedly, often implemented on the circuit level. Should I implement on   *)
(* circuit level? Again, the hardware electronics side is outside my area of  *)
(* expertise.                                                                 *)
(* -------------------------------------------------------------------------- *)

(* -------------------------------------------------------------------------- *)
(* Paper on formally verified ACL2 convolutional codes                        *)
(* -------------------------------------------------------------------------- *)
(* Content:                                                                   *)
(*                                                                            *)
(* The purpose of this work is to design formally verifiable error correcting *)
(* codes to correct soft errors in memories                                   *)
(*                                                                            *)
(* Soft errors cause the memory to temporarily return an incorrect bit, due   *)
(* interference from outside sources                                          *)
(*                                                                            *)
(* One of the most notable (but irrelevant to me) features of this work is    *)
(* that it explicitly involves the handling of memories. In particular it     *)
(* implements them in a formal record-based memory model.                     *)
(*                                                                            *)
(* Typically, encoding/decoding of convolutional codes happens over several   *)
(* clock cycles. However, this implementation uses a combinatorial method.    *)
(* My understanding is that this increases the rate at which error correction *)
(* can occur.                                                                 *)
(*                                                                            *)
(* In this implementation, rather than taking a stream of bits as input, it   *)
(* breaks it down into blocks. Encoding starts in state 00, and two null bits *)
(* are placed at the end, in order to provide enough padding to properly      *)
(* encode all of the bits. This paper refers to this technique as tail-biting,*)
(* but I believe that this is incorrect. This technique appears to be         *)
(* zero-tailed encoding (see the mathworks page on tail-biting convolutional  *)
(* coding).                                                                   *)
(*                                                                            *)
(* Mentions that output bits may be interleaved to minimize data corruption.  *)
(* Not entirely sure what this means. Source is a patent, hard to find        *)
(* description of what interleaving precisely means.                          *)
(*                                                                            *)
(* Decoder is based on another paper: "Convolutional Coding for SEU           *)
(* mitigation"                                                                *)
(*                                                                            *)
(* -------------------------------------------------------------------------- *)
(* Questions/things to discuss:                                               *)
(*                                                                            *)
(* Not based on a stream of bits, but rather based on a sequence of blocks.   *)
(*                                                                            *)
(* Combinatorial rather than sequential                                       *)
(* -------------------------------------------------------------------------- *)

(* -------------------------------------------------------------------------- *)
(* Paper cited as decoder for formally verified ACL2 convolutional codes      *)
(* -------------------------------------------------------------------------- *)
(* Discusses ECCs as a method for correcting soft errors                      *)
(*                                                                            *)
(* In this case, tail-biting seems to refer to a circular data word, where    *)
(* the last bit wraps around to the first one.                                *)
(*                                                                            *)
(*                                                                            *)
(*                                                                            *)
(*                                                                            *)
(* -------------------------------------------------------------------------- *)
(*                                                                            *)
(* -------------------------------------------------------------------------- *)

(* -------------------------------------------------------------------------- *)
(* Textbook chapter on convolutional codes                                    *)
(* -------------------------------------------------------------------------- *)
(*                                                                            *)
(*                                                                            *)
(*                                                                            *)
(*                                                                            *)
(*                                                                            *)
(*                                                                            *)
(*                                                                            *)
(* -------------------------------------------------------------------------- *)
(*                                                                            *)
(* -------------------------------------------------------------------------- *)

(* -------------------------------------------------------------------------- *)
(* Random bonus mathematical observation: surely revolutions are a more       *)
(* natural method of measuring angles than radians are?                       *)
(*                                                                            *)
(* On the other hand, apparently there are a lot of things that are more      *)
(* natural with radians. For example, the derivative of sin x is only cos x   *)
(* if you are using radians. Otherwise it's an expression involving pi, I     *)
(* believe.                                                                   *)
(* -------------------------------------------------------------------------- *)


val _ = export_theory();


